# -*- coding: utf-8 -*-
"""Analyze_RBPs_Fimo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15L4e0ydERD8KmsD4dAo1nkm3E_Yg0Nuo
"""

#install
!pip install numpy
!pip install seaborn
!pip install scipy
!pip install logomaker
import numpy as np
import csv
import os
from collections import defaultdict
from scipy.special import logit
import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt
import logomaker as lm

#initialize df
df = pd.DataFrame(columns=['motif_name', 'sequence', 'start', 'stop', 'strand', 'score', 'pvalue', 'qvalue'])
#get fimo results path
fimo_out='/content/drive/MyDrive/MotifSearch/fimo_results/output_singles_redo.tsv'
df=pd.read_csv(fimo_out, sep='\t')
#plot distribution of RBP hits
ax1 = plt.axes()
x_axis = ax1.axes.get_xaxis()
x_axis.set_visible(False)
categories = df['motif_name'].value_counts().index
counts = df['motif_name'].value_counts().values
plt.bar(categories, counts)
plt.ylim(0,11000)
plt.title('RBP hit distribution')
plt.xlabel('RBPs')
plt.ylabel('Counts of hits')
plt.show()

#read in fimo results
hek_merged_dpsi_file='/content/drive/MyDrive/MotifSearch/hek_merged_dPSIs.csv'
hek_raw_psi_file='/content/drive/MyDrive/MotifSearch/hek_merged_raw_offset_PSIs.csv'
df_psi = pd.read_csv(hek_merged_dpsi_file,low_memory=False) #dpsis only, col mean is the raw PSI averaged across exon families
df_raw_psi= pd.read_csv(hek_raw_psi_file,low_memory=False) #psis

#merged fimo results with dPSI results

df_merged= pd.merge(df.loc[:,['motif_name','sequence','qvalue','start','stop']], df_psi.loc[:,['Reference','Mean','dPSI','delta_logit_psi','seq_type','event_id','seqs', 'intron1_start', 'intron1_end','exon_start','exon_end','intron2_start']], left_on='sequence', right_on='Reference')
df_merged_raw_psi= pd.merge(df.loc[:,['motif_name','sequence','qvalue','start','stop']], df_raw_psi.loc[:,['Reference','Mean','seq_type','event_id','seqs','intron1_start', 'intron1_end','exon_start','exon_end','intron2_start']], left_on='sequence', right_on='Reference')


#just dPSIs
df_psi_new=df_psi.loc[:,['Reference','Mean','dPSI','delta_logit_psi','seq_type','event_id','seqs','intron1_start', 'intron1_end','exon_start','exon_end','intron2_start']].reset_index(drop=True)


#just fimo results
df_m_new=df_merged.loc[:,['Reference','Mean','dPSI','delta_logit_psi','seq_type','event_id','seqs','intron1_start', 'intron1_end','exon_start','exon_end','intron2_start']].reset_index(drop=True)

#split fimo results into regions intron1,intron2 and exon results
def split_results_by_loc(df):
  print(len(df))
  intron1_fimo_results=pd.DataFrame()
  intron2_fimo_results=pd.DataFrame()
  exon_fimo_results=pd.DataFrame()
  #grabs intron spanning fimo hits (blocking off the 2nts of the splice junction)
  df_intron1 =df[(df['start'] >= df['intron1_start']) & (df['stop'] <= (df['intron1_end']-2))]
  df_intron2 =df[(df['start'] >= (df['intron2_start']+2)) & (df['stop'] <= 161)]
  df_exon =df[(df['start'] >= (df['exon_start']+2)) & (df['stop'] <= (df['exon_end']-2))]
  df_5ss=df[(df['start'] > (df['intron1_end']-2)) & (df['start'] < (df['exon_start']+2)) | (df['stop'] > (df['intron1_end']-2)) & (df['stop'] < (df['exon_start']+2))]
  df_3ss=df[(df['start'] > (df['exon_end']-2)) & (df['start'] < (df['intron2_start']+2)) | (df['stop'] > (df['exon_end']-2)) & (df['stop'] < (df['intron2_start']+2))]
  print(len(df_intron2))
  print(len(df_intron1))
  print(len(df_exon))
  print('rbps not in these regions')
  print(len(df)-(len(df_exon)+len(df_intron2)+len(df_intron1)))
  print(len(df_5ss))
  print(len(df_3ss))
  return df_intron1, df_exon , df_intron2
df_intron1, df_exon , df_intron2=split_results_by_loc(df_merged_raw_psi)

df_dict_by_motif= {cur_id: df_merged_raw_psi[df_merged_raw_psi['motif_name'] ==cur_id] for cur_id in df_merged_raw_psi.motif_name.unique()}
df_dict_intron1_by_motif={cur_id: df_intron1[df_intron1['motif_name'] ==cur_id] for cur_id in df_merged_raw_psi.motif_name.unique()}
df_dict_intron2_by_motif={cur_id: df_intron2[df_intron2['motif_name'] ==cur_id] for cur_id in df_merged_raw_psi.motif_name.unique()}
df_dict_exon_by_motif={cur_id: df_exon[df_exon['motif_name'] ==cur_id] for cur_id in df_merged_raw_psi.motif_name.unique()}
#df_dict_by_event_id= {cur_id: df_merged_raw_psi[df_merged_raw_psi['event_id'] ==cur_id] for cur_id in df_merged_raw_psi.event_id.unique()}

import os.path
from os import path
if path.exists('/content/drive/MyDrive/MotifSearch/swarms_by_motif/') == False:
  os.mkdir('/content/drive/MyDrive/MotifSearch/swarms_by_motif/')
for k,v in df_dict_by_motif.items():
  if not df_dict_exon_by_motif[k].empty:
    exon_hits=df_dict_exon_by_motif[k]
  if not df_dict_intron1_by_motif[k].empty:
    intron1_hits=df_dict_intron1_by_motif[k]
  if not df_dict_intron2_by_motif[k].empty:
    intron2_hits=df_dict_intron2_by_motif[k]
  for id in v['event_id'].unique():
    intron1_hits=intron1_hits[intron1_hits['event_id']==id]
    intron2_hits=intron2_hits[intron2_hits['event_id']==id]
    exon_hits=exon_hits[exon_hits['event_id']==id]
    non_hits=pd.concat([df_psi_new[df_psi_new['event_id']==id],v[v['event_id']==id]]).drop_duplicates(subset=['Reference'],keep=False)  #non-hit variants (no hit in any region (exons, introns, etc.), not just one)
    data=[np.array(exon_hits['Mean']),np.array(intron1_hits['Mean']),np.array(intron2_hits['Mean']),np.array(non_hits['Mean'])]
    if len(intron1_hits)+len(intron2_hits)+len(exon_hits)>=1:
      if len(non_hits)>=1:
        print(k)
        plt.figure()
        sns.stripplot([[],[],[],[]])
        ax=sns.stripplot(data)
        ax.set_xticks(range(4),labels=['exon','intron1','intron2','no hits'])
        plt.title(k + ' ' +id  )
        plt.show()
        ax.figure.savefig('/content/drive/MyDrive/MotifSearch/swarms_by_motif/' +k.split('MOTIF ')[1].split('/')[0].split(';')[0] +'_exon_id_'+id +'.pdf')

for k,v in df_dict_by_motif.items():
  num_hits=[]
  num_no_hits=[]
  num_unique=len(v['event_id'].unique())
  for id in v['event_id'].unique():
    num_hits+=[len(v[v['event_id']==id]['Reference'].unique())]
    num_no_hits+=[len(df_raw_psi[df_raw_psi['event_id']==id]['Reference'].unique())-len(v[v['event_id']==id]['Reference'].unique())]
  names = v['event_id'].unique()
  num_hits, num_no_hits,names = zip(*sorted(zip(num_hits, num_no_hits,names),reverse=True))
  indices = range(len(num_hits))
  # Calculate optimal width
  width = np.min(np.diff(indices))/3.
  fig, ax = plt.subplots()
  ax.bar(indices-width/2.,num_hits ,width,color='b',label='RBP BS found')
  ax.bar(indices+width/2.,num_no_hits ,width,color='r',label='No RBP BS found')
  plt.title(k.split('MOTIF ')[1])
  plt.xlabel(str(num_unique)+' unique exon families')
  plt.xticks([])
  plt.legend(['RBP BS found','No RBP BS found'])
  plt.savefig('/content/drive/MyDrive/MotifSearch/motif_by_family/'+k.split('MOTIF ')[1].split('/')[0].split(';')[0]+'.pdf')

#export
df_merged.to_csv('/content/drive/MyDrive/MotifSearch/fimo_merged_dPSIs.csv') #save merged dPSI and fimo results
print(len(df_merged))
df_merged_raw_psi.to_csv('/content/drive/MyDrive/MotifSearch/fimo_merged_PSIs_with_Refs.csv')

#this cell calculates the RBP hits with and without hits in the reference.
#DataFrameDict_Ref_matches is the dataframe of ddPSIs/sequences with RBPs having hits in the variants reference
#DataFrameDict_No_Ref_matches is the dataframe of dPSIs/sequences with each RBP having NO hits in the corresponding variants reference

import warnings
warnings.filterwarnings("ignore") #some weird formatting in the dataframe caused a bug-- working this out
UniqueNames = df_merged.motif_name.unique()
no_var_df=pd.DataFrame()
DataFrameDict = {elem : pd.DataFrame() for elem in UniqueNames}
DataFrameDict_No_Ref_matches = {elem : pd.DataFrame() for elem in UniqueNames}
DataFrameDict_Ref_matches={elem : pd.DataFrame() for elem in UniqueNames}
DataFrameDict_No_Var_matches={elem : pd.DataFrame() for elem in UniqueNames}
for key in DataFrameDict.keys():
  cur_df=df_merged[:][df_merged.motif_name == key] #all info for seqs with hit on cur RBP
  DataFrameDict[key]=cur_df
  all_event_ids=cur_df.event_id.unique() #all exons families assoc. with RBP hit
  WT_event_ids=cur_df[cur_df['seq_type']=='none'].event_id.unique() #unique exons ids with WT hits on this RBPs
  for WT_event in  WT_event_ids:
    DataFrameDict_Ref_matches[key]=pd.concat([DataFrameDict_Ref_matches[key],cur_df[cur_df['event_id']==WT_event]]) #seqs with hits on the reference
    DataFrameDict_No_Ref_matches[key]= pd.concat([DataFrameDict_Ref_matches[key],cur_df]).drop_duplicates(keep=False) #seqs with no hits on the reference but hits on the variants (knock in)
    all_seqs_in_array_cur_exon_id=df_psi_new[df_psi_new['event_id']==WT_event]
    non_hits_cur_exon_id=pd.concat([all_seqs_in_array_cur_exon_id,DataFrameDict_Ref_matches[key].loc[:,['Reference','Mean','dPSI','delta_logit_psi','seq_type','event_id','seqs']]]).drop_duplicates(subset=['Reference','event_id'],keep=False)  #knock outs, non-hit variants, that have a hit in their reference
    DataFrameDict_No_Var_matches[key]=pd.concat([DataFrameDict_No_Var_matches[key],non_hits_cur_exon_id]).drop_duplicates()
  if not DataFrameDict_No_Ref_matches[key].empty:
    DataFrameDict_No_Ref_matches[key]= pd.concat([DataFrameDict_Ref_matches[key],cur_df]).drop_duplicates(keep=False).dropna(subset=['dPSI'])
  if not DataFrameDict_Ref_matches[key].empty:
    DataFrameDict_Ref_matches[key]=DataFrameDict_Ref_matches[key].dropna(subset=['dPSI'])

def add_dl_mean_sorted(DataFrameDict):
  motif=[]
  mean=[]
  dlpsis=[]
  df_out=pd.DataFrame()
  for k,v in DataFrameDict.items():
    #loop through dict where key is motif and values are the hits for that motif
    if not v.empty:
      v.delta_logit_psi=v.delta_logit_psi.astype(float) #convert to type float for dlPSI
      v.dPSI=v.delta_logit_psi.astype(float) #convert to type float for dPSI dPSIs
      if 'qvalue' in v.columns:
        q_vals=v.qvalue #get list of qvals
      if not 'motif_name' in v.columns:
        v['motif_name']=k
      psis_mean=v.loc[:,'dPSI'].mean() #list of mean dPSI
      print(k)
      print(psis_mean)
      psis_sem=v.loc[:,'dPSI'].sem() #list of sem of dPSI
      print(psis_sem)
      mean=[v.loc[:,'delta_logit_psi'].mean()] #mean delta logit PSI for that RBP
      v["mean_dlpsi"]=mean[0]
      df_out=pd.concat([df_out,v])
  return df_out.dropna(subset=['dPSI'])



#sort values by mean dl psi
df_merged_No_Ref_matches=add_dl_mean_sorted(DataFrameDict_No_Ref_matches)
df_merged_Ref_matches=add_dl_mean_sorted(DataFrameDict_Ref_matches)
df_merged=add_dl_mean_sorted(DataFrameDict)
df_merged_No_Var_matches=add_dl_mean_sorted(DataFrameDict_No_Var_matches)

from typing_extensions import DefaultDict
def effect_size(df_in,fimo_in):
  effect_size_list=[]
  motif_list=[]
  es_dict={}
  df_out=pd.DataFrame(columns=['motif','effect'])
  UniqueNames = fimo_in.motif_name.unique()
  for motif in UniqueNames:
    #get fimo hits for current motif
    cur_motif=fimo_in.loc[fimo_in.index[fimo_in['motif_name']==motif]]
    #get references in current fimo hits
    cur_motif_refs=cur_motif['Reference']
    cur_motif_refs=cur_motif_refs[:].tolist()
    #get PSIs
    cur_motif_data=df_in.loc[df_in.index[df_in['Reference'].isin(cur_motif_refs)]]
    non_motif_data=df_in.loc[df_in.index[~df_in['Reference'].isin(cur_motif_refs)]]
    Mean_PSI_given_motif= cur_motif_data['Mean'].mean() #'Mean' is averaged PSI data between replicates (with offsets)
    Mean_PSI_not_given_motif= non_motif_data['Mean'].mean() #'Mean' is averaged PSI data between replicates (with offsets)
    effect_numer= Mean_PSI_given_motif/(1-Mean_PSI_given_motif)
    effect_denom=Mean_PSI_not_given_motif/(1-Mean_PSI_not_given_motif)
    effect=np.log2(effect_numer/effect_denom)
    df_out.loc[len(df_out.index)] = [motif, effect]
  return df_out


def get_bootstrap_effects(full_psi_input,fimo_results,sample_size,num_boots,samp_name):
  df_all_boots=pd.DataFrame(columns=['motif'])
  for i in range (num_boots):
    name='boot'+str(i)
    df_sampled=full_psi_input.sample(sample_size, replace=True)
    sampled_refs=df_sampled['Reference']
    sampled_fimo = fimo_results[fimo_results['Reference'].isin(sampled_refs)]
    df_cur=effect_size(df_sampled,sampled_fimo)
    df_all_boots= pd.merge(df_all_boots,df_cur.rename(columns={'effect': name}).drop_duplicates(), on=['motif'], how='outer')
  print(df_all_boots)
  df_all_boots.to_csv('/content/drive/MyDrive/MotifSearch/bootstrap_RBP_effects_'+samp_name+'.csv')

  stats=pd.DataFrame()

  stats['motif']=df_all_boots['motif']
  stats['mean']=df_all_boots.mean(axis=1)
  stats['sem']=df_all_boots.sem(axis=1)

  stats['ci95_hi'] = stats['mean'] + 1.96* stats['sem']
  stats['ci95_lo'] = stats['mean'] - 1.96* stats['sem']
  stats=stats.sort_values(by=['mean'])

  stats['motif'] = stats['motif'].str.split("MOTIF").str[1]
  stats['motif']=stats['motif'].str.split("/").str[0]
  stats['motif']=stats['motif'].str.split(";").str[0]
  stats.dropna(axis = 0, how = 'all', inplace = True)

  plt.figure().set_figheight(20)
  plt.figure().set_figwidth(5)
  plt.yticks(fontsize=0.5)
  plt.errorbar(stats['mean'],stats['motif'], xerr=(stats['mean']-stats['ci95_lo'],-stats['mean']+stats['ci95_hi']),ecolor='green',elinewidth=0.5,linestyle='')
  plt.plot(stats['mean'],stats['motif'],'ro', markersize=2)
  plt.savefig('/content/drive/MyDrive/MotifSearch/motif_effects_'+samp_name+'.pdf')
  #repeat plot but zoom into both ends

  #bottom end
  plt.figure().set_figheight(20)
  plt.figure().set_figwidth(5)
  plt.yticks(fontsize=5)
  stats_bot_25=stats.iloc[:25]
  plt.errorbar(stats_bot_25['mean'],stats_bot_25['motif'], xerr=(stats_bot_25['mean']-stats_bot_25['ci95_lo'],-stats_bot_25['mean']+stats_bot_25['ci95_hi']),ecolor='green',elinewidth=0.5,linestyle='')
  plt.plot(stats_bot_25['mean'],stats_bot_25['motif'],'ro', markersize=2)

  plt.savefig('/content/drive/MyDrive/MotifSearch/motif_effects_zoom_bottom_25_'+samp_name+'.pdf',bbox_inches='tight')
  #top end
  plt.figure().set_figheight(20)
  plt.figure().set_figwidth(5)
  plt.yticks(fontsize=5)
  stats_top_25=stats.iloc[-25:]
  plt.errorbar(stats_top_25['mean'],stats_top_25['motif'], xerr=(stats_top_25['mean']-stats_top_25['ci95_lo'],-stats_top_25['mean']+stats_top_25['ci95_hi']),ecolor='green',elinewidth=0.5,linestyle='')
  plt.plot(stats_top_25['mean'],stats_top_25['motif'],'ro', markersize=2)
  plt.savefig('/content/drive/MyDrive/MotifSearch/motif_effects_zoom_top_25_'+samp_name+'.pdf',bbox_inches='tight')


  return df_all_boots

#bs_out_exon=get_bootstrap_effects(df_psi_new,df_exon,len(df_psi_new),10,'exon_10boots')
bs_out_intron1=get_bootstrap_effects(df_psi_new,df_intron1,len(df_psi_new),10,'intron1_10boots')
bs_out_intron2=get_bootstrap_effects(df_psi_new,df_intron2,len(df_psi_new),10,'intron2_10boots')

'''
bs_out=pd.read_csv('/content/drive/MyDrive/MotifSearch/bootstrap_RBP_effects_200_10bs.csv')
stats=pd.DataFrame()
stats['motif']=bs_out['motif']
stats['mean']=bs_out.mean(axis=1)
stats['sem']=bs_out.sem(axis=1)
stats['ci95_hi'] = stats['mean'] + 1.96* stats['sem']
stats['ci95_lo'] = stats['mean'] - 1.96* stats['sem']
stats=stats.sort_values(by=['mean'])

stats['motif'] = stats['motif'].str.split("MOTIF").str[1]
stats['motif']=stats['motif'].str.split("/").str[0]
stats['motif']=stats['motif'].str.split(";").str[0]
plt.figure().set_figheight(20)
plt.figure().set_figwidth(5)
plt.yticks(fontsize=0.5)
plt.errorbar(stats['mean'],stats['motif'], xerr=(stats['mean']-stats['ci95_lo'],-stats['mean']+stats['ci95_hi']),ecolor='green',elinewidth=0.5,linestyle='')
plt.plot(stats['mean'],stats['motif'],'ro', markersize=2)
plt.savefig('/content/drive/MyDrive/MotifSearch/motif_effects.pdf')'''

#fetch saved boots and reformat
def load_bootstrap_data(path):
  stats=pd.DataFrame()
  df_all_boots=pd.read_csv(path)
  df_all_boots=df_all_boots.loc[:, ~df_all_boots.columns.str.contains('^Unnamed')]
  df_all_boots=df_all_boots.set_index('motif')
  #stats['mean']=df_all_boots.mean(axis=1)
  stats=pd.concat([stats, df_all_boots.mean(axis=1).rename('mean')], axis=1)
  stats=pd.concat([stats, df_all_boots.sem(axis=1).rename('sem')], axis=1)
  stats['ci95_hi'] = stats['mean'] + 1.96* stats['sem']
  stats['ci95_lo'] = stats['mean'] - 1.96* stats['sem']
  stats=stats.sort_values(by=['mean'])
  stats.reset_index(inplace=True)
  stats=stats.rename(columns = {'index':'motif'})
  stats['motif_short'] = stats['motif'].str.split("MOTIF").str[1]
  stats['motif_short']=stats['motif_short'].str.split("/").str[0]
  stats['motif_short']=stats['motif_short'].str.split(";").str[0]
  stats.dropna(axis = 0, how = 'all', inplace = True)
  return stats

def plot_specific_RBP(rbpnames,data,out_file_path):
  for rbp in rbpnames:
    print(rbp[0])
    rbp_data= data[data['motif'].str.contains(rbp[0],case=False)]
    if len(rbp_data)>=1:
      plt.figure().set_figheight(20)
      plt.figure().set_figwidth(5)
      plt.yticks(fontsize=200/(len(rbp_data)))
      plt.errorbar(rbp_data['mean'],rbp_data['motif'], xerr=(rbp_data['mean']-rbp_data['ci95_lo'],-rbp_data['mean']+rbp_data['ci95_hi']),ecolor='green',elinewidth=0.5,linestyle='')
      plt.plot(rbp_data['mean'],rbp_data['motif'],'ro', markersize=2)
      plt.title(rbp[0])
      plt.savefig(out_file_path+rbp[0]+'_.pdf')
    else:
      print(rbp_data)
  return
rbp_names=[['SRSF3|SRSF7'],['SRSF1|SRSF2'],['RBM4'],['HNRNPDL'],['HNRNPDA1'],['HNRNPF|HNRNPH|HNRNPFH'],['HNRNPK'],['HNRNPI']]
stats_exon=load_bootstrap_data('/content/drive/MyDrive/MotifSearch/bootstrap_RBP_effects_exon_10boots.csv')
plot_specific_RBP(rbp_names,stats_exon,'/content/drive/MyDrive/MotifSearch/bootstrap_RBP_effects_exon_10boots')
stats_intron1=load_bootstrap_data('/content/drive/MyDrive/MotifSearch/bootstrap_RBP_effects_intron1_10boots.csv')
plot_specific_RBP(rbp_names,stats_intron1,'/content/drive/MyDrive/MotifSearch/bootstrap_RBP_effects_intron1_10boots')


#stats_exon=load_bootstrap_data('/content/drive/MyDrive/MotifSearch/bootstrap_RBP_effects_intron1_10boots.csv')

#plot_specific_RBP('RBM22',stats_exon,'/content/drive/MyDrive/MotifSearch/bootstrap_RBP_effects_exon_10boots')

'''#repeat plot but zoom into both ends

#bottom end
plt.figure().set_figheight(20)
plt.figure().set_figwidth(5)
plt.yticks(fontsize=5)
stats_bot_25=stats.iloc[:25]
plt.errorbar(stats_bot_25['mean'],stats_bot_25['motif'], xerr=(stats_bot_25['mean']-stats_bot_25['ci95_lo'],-stats_bot_25['mean']+stats_bot_25['ci95_hi']),ecolor='green',elinewidth=0.5,linestyle='')
plt.plot(stats_bot_25['mean'],stats_bot_25['motif'],'ro', markersize=2)

plt.savefig('/content/drive/MyDrive/MotifSearch/motif_effects_zoom_bottom_25.pdf',bbox_inches='tight')
#top end
plt.figure().set_figheight(20)
plt.figure().set_figwidth(5)
plt.yticks(fontsize=5)
stats_top_25=stats.iloc[-25:]
plt.errorbar(stats_top_25['mean'],stats_top_25['motif'], xerr=(stats_top_25['mean']-stats_top_25['ci95_lo'],-stats_top_25['mean']+stats_top_25['ci95_hi']),ecolor='green',elinewidth=0.5,linestyle='')
plt.plot(stats_top_25['mean'],stats_top_25['motif'],'ro', markersize=2)
plt.savefig('/content/drive/MyDrive/MotifSearch/motif_effects_zoom_top_25.pdf',bbox_inches='tight')'''

PWM_dict=defaultdict()
for i in range (1087):
  i+=1
  with open('/content/drive/MyDrive/MotifSearch/Memes_single_redo2/RBP_merge_single_redo'+str(i)+'.meme') as fm:
    File = csv.reader(fm)
    f_lines=[]
    pwm=[]
    for lines in File:
        f_lines+=lines
    for count, line in enumerate(f_lines[13:]):
      line=line.split('\t')
      pwm+=[[float(x) for x in line]]
    motif=f_lines[11].split('MOTIF ')[1]
    PWM_dict[motif]=pd.DataFrame(pwm,columns=['A','G','C','U'])
logo1=PWM_dict['Attract:A1CF_110']
#logo test
logo = lm.Logo(logo1)

#fetch saved boots and reformat
def load_bootstrap_data(path):
  stats=pd.DataFrame()
  df_all_boots=pd.read_csv(path)
  df_all_boots=df_all_boots.loc[:, ~df_all_boots.columns.str.contains('^Unnamed')]
  df_all_boots=df_all_boots.set_index('motif')
  #stats['mean']=df_all_boots.mean(axis=1)
  stats=pd.concat([stats, df_all_boots.mean(axis=1).rename('mean')], axis=1)
  stats=pd.concat([stats, df_all_boots.sem(axis=1).rename('sem')], axis=1)
  stats['ci95_hi'] = stats['mean'] + 1.96* stats['sem']
  stats['ci95_lo'] = stats['mean'] - 1.96* stats['sem']
  stats=stats.sort_values(by=['mean'])
  stats.reset_index(inplace=True)
  stats=stats.rename(columns = {'index':'motif'})
  stats['motif_short'] = stats['motif'].str.split("MOTIF").str[1]
  stats['motif_short']=stats['motif_short'].str.split("/").str[0]
  stats['motif_short']=stats['motif_short'].str.split(";").str[0]
  stats.dropna(axis = 0, how = 'all', inplace = True)
  return stats

def plot_specific_RBP(rbpnames,data,out_file_path,PWMs):
  for rbp in rbpnames:
    print(rbp[0])
    rbp_data= data[data['motif'].str.contains(rbp[0],case=False)]
    if len(rbp_data)>=1:
      plt.figure().set_figheight(20)
      plt.figure().set_figwidth(5)
      plt.yticks(fontsize=200/(len(rbp_data)))
      plt.errorbar(rbp_data['mean'],rbp_data['motif'], xerr=(rbp_data['mean']-rbp_data['ci95_lo'],-rbp_data['mean']+rbp_data['ci95_hi']),ecolor='green',elinewidth=0.5,linestyle='')
      plt.plot(rbp_data['mean'],rbp_data['motif'],'ro', markersize=2)
      plt.title(rbp[0])
      plt.savefig(out_file_path+rbp[0]+'_.pdf')
      for motif in rbp_data['motif']:
        logo=lm.Logo(PWMs[motif.split('MOTIF ')[1]])

    else:
      print(rbp_data)
  return
rbp_names=[['SRSF3|SRSF7'],['SRSF1|SRSF2'],['RBM4'],['HNRNPDL'],['HNRNPDA1'],['HNRNPF|HNRNPH|HNRNPFH'],['HNRNPK'],['HNRNPI']]
stats_exon=load_bootstrap_data('/content/drive/MyDrive/MotifSearch/bootstrap_RBP_effects_exon_10boots.csv')
plot_specific_RBP(rbp_names,stats_exon,'/content/drive/MyDrive/MotifSearch/bootstrap_RBP_effects_exon_10boots',PWM_dict)



df_merged=df_merged.sort_values('mean_dlpsi')
df_merged_No_Ref_matches=df_merged_No_Ref_matches.sort_values('mean_dlpsi')
df_merged_Ref_matches=df_merged_Ref_matches.sort_values('mean_dlpsi')
df_merged_No_Var_matches=df_merged_No_Var_matches.sort_values('mean_dlpsi')
UniqueNames_New = df_merged.motif_name.unique()
UniqueNames_No_Var=df_merged_No_Var_matches.motif_name.unique()
print(len(UniqueNames_New))
print(len(UniqueNames_No_Var))

min=0
max=0
'''
for motif in UniqueNames_New:
  cur_vals=df_merged.index[df_merged['motif_name']==motif]
  dl_psis=pd.DataFrame(df_merged.mean_dlpsi.loc[cur_vals])
  cur_mean=dl_psis.mean()
  if float(cur_mean.mean_dlpsi)<min:
    min=float(cur_mean.mean_dlpsi)
  if float(cur_mean.mean_dlpsi)>max:
    max=float(cur_mean.mean_dlpsi)'''

#min=df_merged_Ref_matches['mean_dlpsi'].min()
min=df_merged['mean_dlpsi'].min()
#max=df_merged_Ref_matches['mean_dlpsi'].max()
max=df_merged['mean_dlpsi'].max()
print(min)
print(max)

'''import matplotlib.gridspec as grid_spec
import matplotlib as mpl
#gs = grid_spec.GridSpec(len(UniqueNames),1)
fig = plt.figure(figsize=(50,2500))
i = 0
count=0
#creating empty list
fig, axs = plt.subplots(10,1,sharex=True)
fig.set_size_inches(10.5, 15)
s=df_merged.delta_logit_psi.astype('float')
new_cmap = plt.get_cmap('coolwarm_r')
norm = plt.Normalize(min,max)
for motif in UniqueNames_New:
  if i==10:
    plt.savefig('/content/drive/MyDrive/MotifSearch/RBP_plots_no_filter/RBP_plot_num_'+str(count)+'.pdf')
    plt.show()
    fig, axs = plt.subplots(10,1,sharex=True)
    fig.set_size_inches(10.5, 15)
    i=0
    count+=1
  print(i)
  # plotting the distribution
  cur_vals=df_merged.index[df_merged['motif_name']==motif]
  print(cur_vals)
  dl_psis=pd.DataFrame(df_merged.mean_dlpsi.loc[cur_vals])
  cur_mean=dl_psis.mean()
  g=sns.kdeplot(data=(pd.DataFrame(df_merged.delta_logit_psi.loc[cur_vals]).astype('float')),ax=axs[i],warn_singular=False,color='black')
  try:
    line = axs[i].lines[0] # get the first line, there might be more
    x=line.get_xdata()
    y=line.get_ydata()
    axs[i].fill_between(x, y, color=new_cmap(norm(cur_mean))[0],alpha=0.7)
  except:
    print(motif)
  if len(cur_vals)>2:
    axs[i].get_lines()[0].set_color('black')
    g.legend([motif.split('MOTIF')[1].split(';')[0].split('/')[0]+'\n'+'n='+str(len(cur_vals))],fontsize=8,loc='upper left',frameon=False,markerscale=0,handletextpad=0, handlelength=0)
    #g.legend([],[], frameon=False)
    g.set(ylabel=None)
    #g.set(ylim=(0, 1))
    g.set(xlim=(-15, 10))
    g.set_facecolor('white')
    g.tick_params(bottom=False)  # remove the ticks
    sns.set(font_scale =0.6)
    axs[i].axhline(linewidth=4, color="k")
    g.figure.subplots_adjust(wspace=0, hspace=0)
  #axs[i].set_title(motif.split('MOTIF')[1].split(';')[0].split('/')[0], fontsize=4, fontdict={'verticalalignment': 'bottom','horizontalalignment': 'left'})



  i += 1
count+=1
plt.savefig('/content/drive/MyDrive/MotifSearch/RBP_plots_no_filter/RBP_plot_num_'+str(count)+'.pdf')'''

fig, ax = plt.subplots(figsize=(6, 1))
fig.subplots_adjust(bottom=0.5)
cb1 = mpl.colorbar.ColorbarBase(ax, cmap=new_cmap,
                                norm=norm,
                                orientation='horizontal')
cb1.set_label('Mean Delta Logit PSI')
fig.show()
plt.savefig('/content/drive/MyDrive/MotifSearch/RBP_plots_WT_filter/RBP_plot_cmap.pdf')

def plot_kde(UniqueNames_New,motif_dicts,min,max,file_path):
  fig = plt.figure(figsize=(500,250))
  i = 0
  count=0
  fig, axs = plt.subplots(10,len(motif_dicts),sharex=True) #creat 10xn subplots
  fig.set_size_inches(10.5, 15)
  new_cmap = plt.get_cmap('coolwarm_r')
  norm = plt.Normalize(min,max)
  for motif in UniqueNames_New:
    if i==10:
      #break subplots into chunks of 10x3
      plt.savefig(file_path+str(count)+'.pdf')
      plt.show()
      fig, axs = plt.subplots(10,len(motif_dicts),sharex=True)
      fig.set_size_inches(10.5, 10.5)
      i=0
      count+=1
    # plotting the distribution
    for j in range(len(motif_dicts)):
      cur_dict=motif_dicts[j]
      cur_vals=cur_dict.index[cur_dict['motif_name']==motif]
      if len(cur_vals)==0 or cur_vals.empty:
        g=sns.scatterplot(ax=axs[i,j])
        g.set_facecolor('white')
        g.legend([motif.split('MOTIF')[1].split(';')[0].split('/')[0]+'\n'+'n='+str(len(cur_vals))],fontsize=6,loc='upper left',frameon=False,markerscale=0,handletextpad=-2.0, handlelength=0)
      if len(cur_vals)<=3:
        dl_psis=pd.DataFrame(cur_dict.mean_dlpsi.loc[cur_vals])
        cur_mean=dl_psis.mean()
        x_vals=pd.DataFrame(cur_dict.delta_logit_psi.loc[cur_vals]).astype('float').to_numpy().flatten()
        if len(motif_dicts)>1:
          g=sns.scatterplot(x=x_vals, y=np.ones(len(x_vals)),ax=axs[i,j],color=new_cmap(norm(cur_mean))[0])
        if len(motif_dicts)==1:
          g=sns.scatterplot(x=x_vals, y=np.ones(len(x_vals)),ax=axs[i],color=new_cmap(norm(cur_mean))[0])
        g.legend([motif.split('MOTIF')[1].split(';')[0].split('/')[0]+'\n'+'n='+str(len(cur_vals))],fontsize=6,loc='upper left',frameon=False,markerscale=0,handletextpad=-2.0, handlelength=0)
        g.set(ylabel=None)
        g.set(xlim=(-15, 10))
        g.set_facecolor('white')
        g.tick_params(bottom=False)  # remove the ticks
        sns.set(font_scale =0.6)
      if len(cur_vals)>3:
        dl_psis=pd.DataFrame(cur_dict.mean_dlpsi.loc[cur_vals])
        cur_mean=dl_psis.mean()
        if len(motif_dicts)==1:
          g=sns.kdeplot(data=(pd.DataFrame(cur_dict.delta_logit_psi.loc[cur_vals]).astype('float')),ax=axs[i],warn_singular=False,color='black')
        if len(motif_dicts)>1:
          g=sns.kdeplot(data=(pd.DataFrame(cur_dict.delta_logit_psi.loc[cur_vals]).astype('float')),ax=axs[i,j],warn_singular=False,color='black')
        if len(motif_dicts)>1:
          line = axs[i,j].lines[0] # get the first line, there might be more
          x=line.get_xdata()
          y=line.get_ydata()
          axs[i,j].fill_between(x, y, color=new_cmap(norm(cur_mean))[0],alpha=0.7)
          axs[i,j].get_lines()[0].set_color('black')
          axs[i,j].axhline(linewidth=4, color="k")
          g.legend([motif.split('MOTIF')[1].split(';')[0].split('/')[0]+'\n'+'n='+str(len(cur_vals))],fontsize=6,loc='upper left',frameon=False,markerscale=0,handletextpad=-2.0, handlelength=0)

        if len(motif_dicts)==1:
          line = axs[i].lines[0] # get the first line, there might be more
          x=line.get_xdata()
          y=line.get_ydata()
          axs[i].fill_between(x, y, color=new_cmap(norm(cur_mean))[0],alpha=0.7)
          axs[i].get_lines()[0].set_color('black')
          axs[i].axhline(linewidth=4, color="k")
          g.legend([motif.split('MOTIF')[1].split(';')[0].split('/')[0]+'\n'+'n='+str(len(cur_vals))],fontsize=6,loc='upper left',frameon=False,markerscale=0,handletextpad=0, handlelength=0)



        g.set(ylabel=None)
        g.set(xlim=(-15, 10))
        g.set_facecolor('white')
        g.tick_params(bottom=False)  # remove the ticks
        sns.set(font_scale =0.6)
        g.figure.subplots_adjust(wspace=0.25, hspace=0.5)



    i += 1
  count+=1
  plt.savefig(file_path+str(count)+'.pdf')

plot_kde(UniqueNames_New,[df_merged],min,max,'/content/drive/MyDrive/MotifSearch/RBP_plots_no_filter/RBP_plot_num_')

print(len(UniqueNames_New))
motif_dicts=[df_merged_No_Ref_matches,df_merged_Ref_matches, df_merged]
plot_kde(UniqueNames_New,motif_dicts,min,max,'/content/drive/MyDrive/MotifSearch/RBP_plots_WT_filter_redo/RBP_plot_num_')

#plotting knock outs->seqs with hits on the reference but not on the variants
#Unique_names_ko=df_merged_No_Var_matches.motif_name.unique()
motif_dicts_ko=[df_merged_No_Ref_matches,df_merged_No_Var_matches,df_merged_Ref_matches, df_merged]
min=df_merged['mean_dlpsi'].min()
max=df_merged['mean_dlpsi'].max()
plot_kde(UniqueNames_New,motif_dicts_ko,min,max,'/content/drive/MyDrive/MotifSearch/RBP_plots_knock_outs/RBP_plot_num_')

print(df_merged_No_Var_matches)

#print(UniqueNames_New)
'''
cur_vals=df_merged_No_Ref_matches.index[df_merged_No_Ref_matches['motif_name']=='MOTIF Ornament:MSI1_7mer_logo2\n']
print(cur_vals)
df=pd.DataFrame(df_merged_No_Ref_matches.loc[cur_vals])
with pd.option_context('display.max_rows', None,
                       'display.max_columns', None,
                       'display.precision', 3,
                       ):
  print(df)'''