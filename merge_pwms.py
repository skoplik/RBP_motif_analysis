# -*- coding: utf-8 -*-
"""merge_pwms.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1epp0ujxTm8PstZ16azK4fLWLOx8n-_CZ
"""

!pip install pymemesuite
!pip install numpy
!pip install seaborn
!pip install scipy
import numpy as np
import csv
import os
from collections import defaultdict
from scipy.special import logit
import seaborn as sns
from matplotlib import pyplot as plt

def is_float(string):
    try:
        float(string)
        return True
    except ValueError:
        return False

#get file paths
attract_pwms='/content/drive/MyDrive/MotifSearch/ATtRACT/pwm.txt'
attract_db='/content/drive/MyDrive/MotifSearch/ATtRACT/ATtRACT_db.txt'
CISBP='/content/drive/MyDrive/MotifSearch/motif_databases/CISBP-RNA/Homo_sapiens.meme'
Ray_2013='/content/drive/MyDrive/MotifSearch/motif_databases/RNA/Ray2013_rbp_Homo_sapiens.meme'
Ornament_pwms_path='/content/drive/MyDrive/MotifSearch/ornament/PWMs'

#load Ray_2013 meme file
#All meme files start with:

'''MEME version 5.4.1 (Tue Mar 1 19:18:48 2022 -0800)



ALPHABET= ACGT



strands: + -



Background letter frequencies (from uniform background):

A 0.25000 C 0.25000 G 0.25000 U 0.25000'''

matrix_line=[]
Ray_matrix_info=defaultdict(str)
Ray_matrix=defaultdict(list)



'''
def RNA_ENCODE_PWM(v):
  swapped=v
  flipped_v=np.flipud(v)
  swapped[:,[3,2,1,0]] = flipped_v[:,[0,1,2,3]]
  return swapped'''

with open(Ray_2013,'r') as file_ray:
  for line in file_ray:
    if line.strip(): #ignore whitespace lines
      if 'MOTIF' in line:
        matrix_line=[]
        motif_name=line.strip().split('MOTIF')[1].replace(" ","_")
        motif_name=motif_name[1:]
      if 'letter-probability matrix' in line:
        Ray_matrix_info[motif_name]=line.strip()
      if is_float(line.split('\t')[0]):
        matrix_line.append(line.strip().split('\t')[0:4])
        Ray_matrix[motif_name]=np.asarray(matrix_line, dtype=float)

print(Ray_matrix)

#load CISBP
matrix_line1=[]
CISBP_matrix_info=defaultdict(str)
CISBP_matrix=defaultdict(list)
CISBP_url=defaultdict(str)

with open(CISBP,'r') as file_cisbp:
  for line1 in file_cisbp:
    if line1.strip(): #ignore whitespace lines
      if 'MOTIF' in line1:
        matrix_line=[]
        motif_name=line1.strip().split('MOTIF')[1].replace(" ","")
      if 'letter-probability matrix' in line1:
        CISBP_matrix_info[motif_name]=line1.strip()
      if is_float(line1.split('\t')[0]):
        matrix_line1=line1.strip().split('\t')[0:4]
        CISBP_matrix[motif_name].append(np.asarray(matrix_line1,dtype=float))
print(CISBP_matrix)

#Parse attract

at_matrix=defaultdict(list)
at_pwm_ids=defaultdict(str)
at_pwm_org=defaultdict(str)

with open(attract_db,'r') as file_at_ids:
    reader_id = csv.reader(file_at_ids,delimiter='\t')
    next(reader_id, None)  # skip the headers
    for line in reader_id:
      organism=line[3]
      id_code=line[11]
      rbp_name=line[0]+'_'+line[11]
      at_pwm_ids[id_code]=rbp_name
      at_pwm_org[id_code]=organism

with open(attract_pwms,'r') as file_at:
  reader = csv.reader(file_at, delimiter='\t')
  for line in reader:
    if '>' in line[0]:
      cur_mat=[]
      cur_id=line[0].split('>')[1]
    else:
      last_id=cur_id
      line=np.asarray(line,dtype=float)
      cur_mat=np.append(cur_mat,line)
      if at_pwm_org[cur_id]=='Homo_sapiens':
        at_matrix[at_pwm_ids[cur_id]]=cur_mat.reshape(-1,4) #this looks RNA encoded, so leaving it in the current orientation

#Parse ornament
rbp_file_name=defaultdict(str)
Orn_matrix=defaultdict(list)
with open('/content/drive/MyDrive/MotifSearch/ornament/conv.sh','r') as file_or_id:
    reader = csv.reader(file_or_id, delimiter='\t')
    for line in reader:
      rbp_file_name[line[0].split(' ')[2].split(';')[0]]=line[0].split(' ')[1].split('.')[0]

# assign directory
directory = Ornament_pwms_path

# iterate over files in
# that directory

count=0
for filename in os.listdir(directory):
  cur_mat=[]
  f = os.path.join(directory, filename)
  #checking if it is a file
  if os.path.isfile(f):
    #print(str(filename))
    name_of_rbp=rbp_file_name[str(filename)]
    with open(f,'r') as file_or_id:
      reader_or = csv.reader(file_or_id, delimiter='\t')
      next(reader_or, None)  # skip the headers
      for line in reader_or:
        cur_mat=np.append(cur_mat,np.asarray(line[1:5], dtype=float))
        Orn_matrix[name_of_rbp]=cur_mat.reshape(-1,4) #also assuming RNA encoded based on the ornament website and logo images matching pwms.
    count+=1

from IPython.core.magic import validate_type
#merging all dictionaries
#merging Ornament and Attract
PWM_dict_At_merge=defaultdict(str)
PWM_dict_ray_merge=defaultdict(str)


#no self matches in Ornament, Ray2013, or CISBP

#merging self matches in attract
merged_pwms=[]
for k_at,v_at in at_matrix.items():
  key_name=k_at
  if key_name not in merged_pwms:
    for k_at1, v_at1 in at_matrix.items():
      if k_at!=k_at1:
        if np.shape(v_at)==np.shape(v_at1):
          if np.allclose(v_at,v_at1, rtol=0.001, equal_nan=False):
            key_name=key_name+';'+k_at1
            merged_pwms+=[k_at1]
    PWM_dict_At_merge[key_name]=v_at

PWM_dict=defaultdict(str)
matches_list=[]
for k_orn, v_orn in Orn_matrix.items():
  key_name=''
  matches=0
  for k_at, v_at in PWM_dict_At_merge.items():
    if np.shape(v_orn)==np.shape(v_at):
      if np.allclose(v_orn,v_at, rtol=0.001, equal_nan=False):
        key_name='Ornament:'+ k_orn+'/'+'Attract:'+k_at
        matches+=1
        matches_list+=[k_at]
        PWM_dict[key_name]=v_orn
  if matches==0:
      key_name='Ornament:'+k_orn
      PWM_dict[key_name]=v_orn


for k_at, v_at in PWM_dict_At_merge.items():
  if k_at not in matches_list:
    key_name='Attract:'+k_at
    PWM_dict[key_name]=v_at

PWM_dict2=defaultdict(str)
matches_list=[]

#merging that merged dictionary with Ray
for k,v in PWM_dict.items():
  key_name=k+'/'+'Ray2013:'
  matches=0
  for k_ray, v_ray in Ray_matrix.items():
    if np.shape(v)==np.shape(v_ray):
      if np.allclose(v ,v_ray, rtol=0.001, equal_nan=False):
          key_name=key_name+k_ray
          matches+=1
          matches_list+=[k_ray]
          PWM_dict2[key_name]=v_ray
  if matches==0:
    PWM_dict2[k]=v


for k_ray, v_ray in Ray_matrix.items():
  if k_ray not in matches_list:
    key_name='Ray:'+k_ray
    PWM_dict2[key_name]=v_ray
print(len(Ray_matrix))
print(len(matches_list))
print(len(PWM_dict2))

PWM_dict3=defaultdict(str)
matches_list=[]
#merging that dictionary with CISBP
for k,v in PWM_dict2.items():
  key_name=k+'/'+'CISBP:'
  matches=0
  for k_cisbp, v_cisbp in CISBP_matrix.items():
    if np.shape(v)==np.shape(v_cisbp):
      if np.allclose(v ,v_cisbp, rtol=0.001, equal_nan=False):
          key_name=key_name+k_cisbp
          matches+=1
          matches_list+=[k_cisbp]
          PWM_dict3[key_name]=v_cisbp
  if matches==0:
      PWM_dict3[k]=v

for k_cisbp, v_cisbp in CISBP_matrix.items():
  if k_cisbp not in matches_list:
    key_name='CISBP:'+k_cisbp
    PWM_dict3[key_name]=v_cisbp
print(len(CISBP_matrix))
print(len(matches_list))
print(len(PWM_dict3))

print(PWM_dict3)

print(PWM_dict3['Ornament:PTBP1_7mer_logoM228/Ray2013:RNCMPT00269_PTBP1/CISBP:M228_0.6ROD1'])

print(len(PWM_dict3))

#writing mega meme file

#each line must contain:
'letter-probability matrix: alength= 4 w=*width of array*)'
i=0
count=0
f_meme=open('/content/drive/MyDrive/MotifSearch/Memes_single_redo2/RBP_merge_single_redo'+str(i)+'.meme', 'w')
f_meme.write('MEME version 5.4.1 (Tue Mar 1 19:18:48 2022 -0800)\n\n\n\nALPHABET "Basic RNA" RNA-LIKE\nA\nC\nG\nU\nN = ACGU\nEND ALPHABET\n\n\n\nstrands: + \n\n\n\nBackground letter frequencies (from uniform background):\n\nA 0.25000 C 0.25000 G 0.25000 U 0.25000\n')
for k,v in PWM_dict3.items():
  count+=1
  i+=1
  f_meme.close()
  f_meme=open('/content/drive/MyDrive/MotifSearch/Memes_single_redo2/RBP_merge_single_redo'+str(i)+'.meme', 'w')
  print(f_meme)
  f_meme.write('MEME version 5.4.1 (Tue Mar 1 19:18:48 2022 -0800)\n\n\n\nALPHABET "Basic RNA" RNA-LIKE\nA\nC\nG\nU\nN = ACGU\nEND ALPHABET\n\n\n\nstrands: + \n\n\n\nBackground letter frequencies (from uniform background):\n\nA 0.25000 C 0.25000 G 0.25000 U 0.25000\n')
  f_meme.write('\n')
  f_meme.write('\n')
  f_meme.write('MOTIF '+k+'\n\n')
  f_meme.write('letter-probability matrix: alength= 4 w= '+str(len(v))+'\n')
  for j in range (len(v)):
    f_meme.write('\t'.join(str(x) for x in list(v[j].astype(str))))
    f_meme.write('\n')

!zip -r /content/drive/MyDrive/MotifSearch/Memes_single_redo2.zip /content/drive/MyDrive/MotifSearch/Memes_single_redo2

from google.colab import files
files.download("/content/drive/MyDrive/MotifSearch/Memes_single_redo2.zip")

Supertable='/content/drive/MyDrive/MotifSearch/supertable.tsv'
hek1='/content/drive/MyDrive/MotifSearch/HEK293_Rep1_separate_recalc_all_PSIs.txt'
hek2='/content/drive/MyDrive/MotifSearch/HEK293_Rep2_separate_recalc_PSIs_mincov10.txt'
hek4='/content/drive/MyDrive/MotifSearch/HEK293_Rep4_separate_recalc_PSIs_mincov10.txt'
hela='/content/drive/MyDrive/MotifSearch/HeLa_Rep2_separate_recalc_PSIs_mincov10.txt'
k562='/content/drive/MyDrive/MotifSearch/K562_Rep2_separate_recalc_PSIs_mincov10.txt'
mcf7='/content/drive/MyDrive/MotifSearch/MCF7_Rep1_separate_recalc_PSIs_mincov10.txt'

import pandas as pd
df_st = pd.read_csv(Supertable, sep='\t')
full_seqs=pd.DataFrame()
full_seqs['Reference']=np.arange(1, len(df_st) + 1)
full_seqs['seqs']= pd.DataFrame(df_st['intron1'] + df_st['exon']+  df_st['intron2'])
full_seqs['event_id']=pd.DataFrame(df_st['event_id'])
full_seqs['seq_type']=pd.DataFrame(df_st['snp'])
full_seqs['intron1_start']= 0
full_seqs['intron1_end']=df_st['intron1'].apply(len)
full_seqs['exon_start']=df_st['intron1'].apply(len) +1
full_seqs['exon_end']=df_st['intron1'].apply(len)+ df_st['exon'].apply(len)
full_seqs['intron2_start']= df_st['intron1'].apply(len) +1 + df_st['exon'].apply(len)

hek_all_merge_psi=pd.DataFrame()
hek_dpsi=pd.DataFrame()
#print(full_seqs)
print(full_seqs)


hek1_df=pd.read_csv(hek1, sep='\t')
hek2_df=pd.read_csv(hek2, sep='\t')
hek4_df=pd.read_csv(hek4, sep='\t')
hela_df=pd.read_csv(hela, sep='\t')
k562_df=pd.read_csv(k562, sep='\t')
mcf7_df=pd.read_csv(mcf7, sep='\t')


def offset_psis(rep_df):
  psis=[]
  for index, row in rep_df.iterrows():
    cov=float(row['Coverage'])
    psi=float(row['PSI'])
    included=cov*psi
    excluded=cov-included
    included_offset=included+0.5
    excluded_offset=excluded+0.5
    offset_psi=included_offset/(included_offset+excluded_offset)
    psis+=[offset_psi]
  rep_df['Offset PSIs']=psis
  return rep_df

hek1_df=offset_psis(hek1_df)
hek2_df=offset_psis(hek2_df)
hek4_df=offset_psis(hek4_df)
hek_1_2=pd.merge(hek1_df[['Reference', 'Offset PSIs']],hek2_df[['Reference', 'Offset PSIs']], on="Reference",how="inner")
hek_1_2_4=pd.merge(hek_1_2,hek4_df[['Reference', 'Offset PSIs']], on="Reference",how="inner")
hek_1_2_4['Mean']= hek_1_2_4.iloc[:, [1,2,3]].mean(axis=1)

merged_offset_psis=pd.merge(hek_1_2_4[['Reference','Mean']],full_seqs[['Reference', 'seqs','event_id','seq_type','intron1_start', 'intron1_end','exon_start','exon_end','intron2_start' ]], on="Reference",how="inner")
merged_offset_psis.to_csv('/content/drive/MyDrive/MotifSearch/hek_merged_raw_offset_PSIs.csv')

from pandas.core.series import pandas
def get_dpsi(rep_df,fullseqs_df):
  merge_psi=pd.merge(rep_df[['Reference','Mean']],full_seqs[['Reference', 'seqs','event_id','seq_type','intron1_start', 'intron1_end','exon_start','exon_end','intron2_start']], on="Reference",how="inner")
  wts=merge_psi.index[merge_psi['seq_type']=='none'].tolist()
  for wt_idx in wts:
    wt_psi=merge_psi.loc[[wt_idx],['Mean']]
    wt_psi=float(wt_psi['Mean'])
    event_id=merge_psi.loc[[wt_idx],['event_id']]
    cur_vars=merge_psi.index[merge_psi['event_id']==str(event_id.iloc[0]['event_id'])].tolist()
    cur_vars.remove(wt_idx) #remove wt seqs from variant list
    merge_psi.loc[wt_idx,'dPSI']='NAN'
    merge_psi.loc[wt_idx,'delta_logit_psi']='NAN'
    for var in cur_vars:
      var_psi=merge_psi.loc[[var],['Mean']]
      var_psi=float(var_psi['Mean'])
      dpsi=var_psi-wt_psi
      delta_logit_psi=logit(var_psi)-logit(wt_psi)
      merge_psi.loc[var,'dPSI']=dpsi
      merge_psi.loc[var,'delta_logit_psi']=delta_logit_psi
  return merge_psi

hek_merged_dpsis=get_dpsi(hek_1_2_4,full_seqs)
hek_merged_dpsis.to_csv('/content/drive/MyDrive/MotifSearch/hek_merged_dPSIs.csv')

def convert_to_rna(dna):
  new = ""
  for i in dna:
      if i not in 'ATGC':
          new = "Invalid Input"
          break
      if i == 'T':
          new += 'U'
      else:
          new += i
  return new

with open('/content/drive/MyDrive/MotifSearch/input_fimo.fasta', 'w') as fasta:
    for i in range(len(hek_merged_dpsis['Reference'])):
      fasta.write('>'+str(hek_merged_dpsis.loc[i,'Reference'])+ '\n'+ convert_to_rna(hek_merged_dpsis.loc[i,'seqs'])+ '\n')

for i in range(len(hek_merged_dpsis['Reference'])):
  with open('/content/drive/MyDrive/MotifSearch/single_seq_fastas_2/input_fimo_'+ str(hek_merged_dpsis.loc[i,'Reference']) +'_.fasta', 'w') as fasta:
      fasta.write('>'+str(hek_merged_dpsis.loc[i,'Reference'])+ '\n'+ convert_to_rna(hek_merged_dpsis.loc[i,'seqs'])+ '\n')

for i in range(len(hek_merged_dpsis['Reference'])):
  with open('single_seq_fastas_2/input_fimo_'+ str(hek_merged_dpsis.loc[i,'Reference']) +'_.fasta', 'w') as fasta:
      fasta.write('>'+str(hek_merged_dpsis.loc[i,'Reference'])+ '\n'+ convert_to_rna(hek_merged_dpsis.loc[i,'seqs'])+ '\n')
  print(str(hek_merged_dpsis.loc[i,'Reference']))

!zip -r /content/single_seq_fastas_2.zip /content/single_seq_fastas_2

from google.colab import files
files.download("/content/single_seq_fastas_2.zip")

with open('/content/drive/MyDrive/MotifSearch/input_fimo_WT.fasta', 'w') as fasta:
    for i in range(len(hek_merged_dpsis['Reference'])):
      if hek_merged_dpsis.loc[i,'seq_type']=='none':
        fasta.write('>'+str(hek_merged_dpsis.loc[i,'Reference'])+ '\n'+ convert_to_rna(hek_merged_dpsis.loc[i,'seqs'])+ '\n')

#analyze/sort results fimo
#sorting by p values
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

df_fimo= pd.read_csv('/content/drive/MyDrive/MotifSearch/fimo_output_06102023/fimo.tsv',delimiter='\t')
df_fimo=df_fimo.sort_values(['sequence_name'])
print(df_fimo)
cur_event_id=''
q_val=defaultdict(list)
st_index_qv=defaultdict(list)
for index in range(len(df_fimo)):
  super_tab_index=df_fimo.iloc[index]['sequence_name']
  event_id=hek_merged_dpsis.loc[hek_merged_dpsis.Reference == super_tab_index, 'event_id']
  motif=df_fimo.iloc[index]['motif_id']
  q_value=float(df_fimo.iloc[index]['q-value'])
  if event_id.empty:
    q_val['NA']+=[q_value]
    print('no event id')
  else:
    q_val[event_id.iloc[0] + '_'+ motif]+=[q_value]
    st_index_qv[event_id.iloc[0] +'_'+ motif]+=[int(super_tab_index)]

print(st_index_qv)